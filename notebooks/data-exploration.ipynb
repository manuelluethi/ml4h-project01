{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8294b471-70d0-4c4d-a816-4fa7d7743d63",
   "metadata": {},
   "source": [
    "## Exploratory data analysis and preparations\n",
    "In this notebook, we perform some exploratory data analysis together with\n",
    "basic preliminary transformations. These include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde1ceb-27fc-41cd-872a-33cc97f1f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7651892",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "# Important directories\n",
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "LOG_DIR = os.path.join(ROOT_DIR, 'logs')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5c372bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "active-py"
    ]
   },
   "source": [
    "# Only in command line mode:\n",
    "# os.getcwd() doesn't work if the script is run from the command line.\n",
    "# This does the same as above for CLI and isn't needed nor does it work in the\n",
    "# notebook.\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "LOG_DIR = os.path.join(ROOT_DIR, 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85aa7d2-417f-4511-b663-7a77cf0816e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logger = logging.getLogger('data-exploration-logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "if logger.hasHandlers():\n",
    "    # If the logger already has handlers, remove them\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "if not logger.hasHandlers():\n",
    "    # Create a directory for logs if it doesn't exist\n",
    "    try:\n",
    "        os.mkdir(LOG_DIR)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Create a file handler\n",
    "    log_file = os.path.join(LOG_DIR, 'data-exploration.log')\n",
    "    fh = logging.FileHandler(log_file, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "\n",
    "    # Create a console handler\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.CRITICAL)\n",
    "\n",
    "    # Create a formatter and set it for both handlers\n",
    "    log_format = '%(asctime)s - %(name)s - %(levelname)s:\\n\\t\\t%(message)s'\n",
    "    formatter = logging.Formatter(log_format)\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "\n",
    "    # Add the handlers to the logger\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "\n",
    "# Function to load the datasets\n",
    "def loadData():\n",
    "    names = ['a', 'b', 'c']\n",
    "    dataSets = []\n",
    "    for s in names:\n",
    "        featuresPath = os.path.join(DATA_DIR, f'set-{s}.parquet.gzip')\n",
    "        labelsPath = os.path.join(DATA_DIR, f'set-{s}-outcomes.parquet.gzip')\n",
    "        dfFeatures = pd.read_parquet(featuresPath)\n",
    "        dfLabels = pd.read_parquet(labelsPath)\n",
    "        dataSets.append([dfFeatures, dfLabels])\n",
    "    return dataSets\n",
    "\n",
    "\n",
    "# we load the various data sets\n",
    "dataSets = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10686c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Preperations:\n",
    "# A list of all the time series variables to consider\n",
    "LIST_VARIABLE_TS = [\n",
    "    'ALP', 'ALT', 'AST', 'Albumin', 'BUN', 'Bilirubin',\n",
    "    'Cholesterol', 'Creatinine', 'DiasABP', 'FiO2', 'GCS', 'Glucose',\n",
    "    'HCO3', 'HCT', 'HR', 'ICUType', 'K', 'Lactate', 'MAP', 'MechVent',\n",
    "    'Mg', 'NIDiasABP', 'NIMAP', 'NISysABP', 'Na', 'PaCO2', 'PaO2', 'Platelets',\n",
    "    'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI', 'TroponinT', 'Urine',\n",
    "    'WBC', 'pH'\n",
    "]\n",
    "\n",
    "# A list of static variables\n",
    "LIST_VARIABLE_STATIC = [\n",
    "    'Age', 'Gender', 'Height', 'Weight'\n",
    "]\n",
    "\n",
    "# A list of keys:\n",
    "# RecordID indexes the individual times series\n",
    "# Hour is the time stamp to be used -- note that we will have to normalize\n",
    "# the variable Time which is in format hh:mm after admission to hourly\n",
    "# variables\n",
    "LIST_VARIABLE_KEYS = [\n",
    "    'RecordID', 'Hour'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b5fd3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Data exploration\n",
    "We visualize the time series data using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56b201-4cdd-44cb-9744-d71987dc0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplotTimeSeries(ax, data, variable, title=None):\n",
    "    'Create a sequence of boxplots for a given time series variable.'\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    df = data[['Hour', variable]].copy(deep=True)\n",
    "    # We normalize the hourly data around its median for better display\n",
    "    # Also, we only use the inner 95% around the median\n",
    "    medians = df.groupby('Hour')[variable].transform('median')\n",
    "    df[variable] = df[variable] - medians\n",
    "    df['quantile_low'] = df.groupby('Hour')[variable].transform(\n",
    "        'quantile', 0.025\n",
    "    )\n",
    "    df['quantile_high'] = df.groupby('Hour')[variable].transform(\n",
    "        'quantile', 0.975\n",
    "    )\n",
    "    # We drop everything outside the 95% quantile range\n",
    "    df = df[pd.isna(df[variable]) | (df[variable] >= df['quantile_low']) &\n",
    "            (df[variable] <= df['quantile_high'])]\n",
    "    plt = sns.boxplot(ax=ax, data=df, x='Hour', y=variable)\n",
    "    plt.set_title(title\n",
    "                  if title\n",
    "                  else f'Distribution of {variable} around its median')\n",
    "    plt.set_xlabel(\"\")\n",
    "    plt.set_ylabel(\"\")\n",
    "    # we symmetrically set the y-axis limits\n",
    "    y_abs_max = np.max((np.abs(df[variable]).max(), 0.05))\n",
    "    plt.set_ylim(-y_abs_max, y_abs_max)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c7fc4-a0d7-4615-92e4-62a9b933b48d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def boxPlotTimeSeriesMultiple(data, variables, title=None):\n",
    "    'Create a stack of boxplots for multiple time series variables.'\n",
    "    n = len(variables)\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=1, figsize=(12, 3 * n))\n",
    "    'for each variable, create a boxplot and add it to the stacked plot'\n",
    "    for i, variable in enumerate(variables):\n",
    "        plot = boxplotTimeSeries(axes[i], data, variable, f'{variable}')\n",
    "        axes[i].tick_params(axis='x', labelbottom=False)\n",
    "    fig.suptitle(title if title else\n",
    "                 ('Boxplots of Time Series Variables'\n",
    "                  'around the hourly median'),\n",
    "                 fontsize=16)\n",
    "    # Adjust vertical spacing of the plots and reduce the top due to supposedly\n",
    "    # known issue that the suptitle is plotted above an empty first plot. I\n",
    "    # couldn't extract this info from the matplotlib documentation.\n",
    "    fig.subplots_adjust(hspace=0.2, top=1 - 1 / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c8de5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Boxplots of time series variables\n",
    "We plot the boxplots of the time series variables around their hourly median\n",
    "for qualitative assessment of questions like homoskedasticity vs.\n",
    "heteroskedasticity and missingness. We note that some variables are measured\n",
    "very irregularly and that most variables are highly heteroskedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc56a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "title = ('Hourly distributions of time series variables around '\n",
    "         'their hourly median')\n",
    "# Number of variables to plot\n",
    "boxPlotTimeSeriesMultiple(dataSets[0][0],\n",
    "                          LIST_VARIABLE_TS,\n",
    "                          title=title)\n",
    "\n",
    "\n",
    "# ## [markdown]\n",
    "# ### Missingness\n",
    "# For better understanding of missingness, we plot a heatmap for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ecdadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingHeatMap(ax, data, variable, title=None):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    df = data[['Hour', variable]].copy(deep=True)\n",
    "    df['missing'] = df[variable].isna().astype(int)\n",
    "    grouped = df.groupby('Hour')['missing'].agg(['sum', 'count'])\n",
    "    grouped['pct_missing'] = grouped['sum'] / grouped['count']\n",
    "    heatmap_data = grouped.pivot_table(columns='Hour', values='pct_missing')\n",
    "    plt = sns.heatmap(heatmap_data,\n",
    "                      vmin=0, vmax=1,\n",
    "                      cmap='Reds',\n",
    "                      ax=ax,\n",
    "                      cbar=True)\n",
    "    plt.set_title(title\n",
    "                  if title\n",
    "                  else f'Distribution of {variable} around its median')\n",
    "    plt.set_xlabel(\"\")\n",
    "    plt.set_ylabel(\"\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cceb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingHeatMapMultiple(data, variables, title=None):\n",
    "    'Create a stack of heatmaps for multiple time series variables.'\n",
    "    n = len(variables)\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=1, figsize=(12, 2 * n))\n",
    "    for i, variable in enumerate(variables):\n",
    "        plot = missingHeatMap(axes[i], data, variable, f'{variable}')\n",
    "        axes[i].tick_params(axis='x', labelbottom=False)\n",
    "    fig.suptitle(title if title else\n",
    "                 ('Heatmaps of Missingness of Time Series Variables'),\n",
    "                 fontsize=16)\n",
    "    fig.subplots_adjust(hspace=0.2, top=1 - 1 / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Heatmaps of Missingness of Time Series Variables'\n",
    "missingHeatMapMultiple(dataSets[0][0], LIST_VARIABLE_TS, title=title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
